{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vegan111-vegan11/rag/blob/main/%EC%9D%B4%EC%A0%84_%EB%8C%80%ED%99%94%EB%A5%BC_%EA%B8%B0%EC%96%B5%ED%95%98%EB%8A%94_Langchain_%EC%82%AC%EC%9A%A9%EB%B2%95_4%EA%B0%80%EC%A7%80_%7C_%EB%81%9D%EB%A7%90%EC%9E%87%EA%B8%B0_%EC%B1%97%EB%B4%87_%EA%B5%AC%ED%98%84%ED%95%98%EA%B8%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_openai\n",
        "!pip install langchain_community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ttQhY7GjOOji",
        "outputId": "d69a614c-ba0f-4b4e-b0b6-c402b3a1bd6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.2.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting langchain-core<0.4.0,>=0.3.9 (from langchain_openai)\n",
            "  Downloading langchain_core-0.3.9-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting openai<2.0.0,>=1.40.0 (from langchain_openai)\n",
            "  Downloading openai-1.51.1-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain_openai)\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.9->langchain_openai) (6.0.2)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.9->langchain_openai)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.125 (from langchain-core<0.4.0,>=0.3.9->langchain_openai)\n",
            "  Downloading langsmith-0.1.132-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.9->langchain_openai) (24.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.9->langchain_openai) (2.9.2)\n",
            "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain-core<0.4.0,>=0.3.9->langchain_openai)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.9->langchain_openai) (4.12.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai<2.0.0,>=1.40.0->langchain_openai)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai<2.0.0,>=1.40.0->langchain_openai)\n",
            "  Downloading jiter-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (4.66.5)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.9.11)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->langchain_openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->langchain_openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain_openai) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain_openai)\n",
            "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain_openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.9->langchain_openai)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.9->langchain_openai)\n",
            "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.9->langchain_openai)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.9->langchain_openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.9->langchain_openai) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.2.3)\n",
            "Downloading langchain_openai-0.2.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.9-py3-none-any.whl (401 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.8/401.8 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.51.1-py3-none-any.whl (383 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.7/383.7 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (326 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m326.6/326.6 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading langsmith-0.1.132-py3-none-any.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tenacity, orjson, jsonpointer, jiter, h11, tiktoken, requests-toolbelt, jsonpatch, httpcore, httpx, openai, langsmith, langchain-core, langchain_openai\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 jiter-0.6.0 jsonpatch-1.33 jsonpointer-3.0.0 langchain-core-0.3.9 langchain_openai-0.2.2 langsmith-0.1.132 openai-1.51.1 orjson-3.10.7 requests-toolbelt-1.0.0 tenacity-8.5.0 tiktoken-0.8.0\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.35)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.10.8)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting langchain<0.4.0,>=0.3.1 (from langchain_community)\n",
            "  Downloading langchain-0.3.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.6 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.3.9)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.1.132)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.26.4)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.5.2-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (8.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.13.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain<0.4.0,>=0.3.1->langchain_community)\n",
            "  Downloading langchain_text_splitters-0.3.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.1->langchain_community) (2.9.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.6->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.6->langchain_community) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.6->langchain_community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (3.10.7)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (1.0.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.0.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.6->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.1->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.1->langchain_community) (2.23.4)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.2.2)\n",
            "Downloading langchain_community-0.3.1-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading langchain-0.3.2-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.5.2-py3-none-any.whl (26 kB)\n",
            "Downloading langchain_text_splitters-0.3.0-py3-none-any.whl (25 kB)\n",
            "Downloading marshmallow-3.22.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, typing-inspect, pydantic-settings, dataclasses-json, langchain-text-splitters, langchain, langchain_community\n",
            "Successfully installed dataclasses-json-0.6.7 langchain-0.3.2 langchain-text-splitters-0.3.0 langchain_community-0.3.1 marshmallow-3.22.0 mypy-extensions-1.0.0 pydantic-settings-2.5.2 python-dotenv-1.0.1 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-...\""
      ],
      "metadata": {
        "id": "dTxPYf8IRefE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. 환경설정"
      ],
      "metadata": {
        "id": "YJM11xQ_qWWz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Langchain 제공 기능"
      ],
      "metadata": {
        "id": "vyTg2PGOqbsi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "참고 자료 : https://python.langchain.com/v0.2/docs/how_to/chatbots_memory/"
      ],
      "metadata": {
        "id": "AItlxxNmRLeF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1) Message passing\n",
        "- 이전 대화 내용을 chain에 넘겨주는 것\n",
        "\n",
        "- The simplest form of memory is simply passing chat history messages into a chain."
      ],
      "metadata": {
        "id": "N5XYv0azqf3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "chat = ChatOpenAI(model=\"gpt-4o\") # gpt-3.5-turbo-0125"
      ],
      "metadata": {
        "id": "bnr2xJAmRM5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"You are a helpful assistant. Answer all questions to the best of your ability. YOU MUST ANSWER IN KOREAN.\",\n",
        "        ),\n",
        "        (\"placeholder\", \"{messages}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "chain = prompt | chat\n",
        "\n",
        "ai_msg = chain.invoke(\n",
        "    {\n",
        "        \"messages\": [\n",
        "            (\n",
        "                \"human\",\n",
        "                \"일본어로 '잘 먹겠습니다.' 어떻게 말해? 한글 발음도 함께 말해줘.\",\n",
        "            ),\n",
        "            (\"ai\",  \"いただきます (이타다키마스)\"),\n",
        "            (\"human\", \"내가 방금 뭐라고 했지?\"),\n",
        "        ],\n",
        "    }\n",
        ")\n",
        "print(ai_msg.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mphlBET1RY8U",
        "outputId": "db12cc1f-a5b4-4465-9989-1a369a64d11a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "당신은 일본어로 '잘 먹겠습니다.'라는 표현을 물어보셨습니다. 그리고 이에 대한 답으로 일본어로는 \"いただきます\" (이타다키마스)라고 말한다고 알려드렸습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ai_msg = chain.invoke(\n",
        "    {\n",
        "        \"messages\": [\n",
        "            (\n",
        "                \"human\",\n",
        "                \"내 이름은 공원나연이고, AI를 알려주는 유튜브를 운영하고 있어.\",\n",
        "            ),\n",
        "            (\"ai\",  \"그렇군요. 흥미로운데요?\"),\n",
        "            (\"human\", \"내 이름이 뭐라고?\"),\n",
        "        ],\n",
        "    }\n",
        ")\n",
        "print(ai_msg.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-nxFkBPTnL_",
        "outputId": "06c9ef97-8fa3-4d78-a96b-41e219124fcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "당신의 이름은 공원나연입니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 응용 : 대화 쌓일 때마다 히스토리 저장하도록 구현"
      ],
      "metadata": {
        "id": "uzZlHV2vMP5p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history_list = []\n",
        "while(True):\n",
        "    user_input = input()\n",
        "    if user_input == \"종료\": break\n",
        "    history_list.append(\n",
        "        (\n",
        "            \"human\",\n",
        "            user_input,\n",
        "        )\n",
        "    )\n",
        "    print(\"## CHAT_HISTORY ##\")\n",
        "    print(history_list, \"\\n\")\n",
        "    ai_msg = chain.invoke(\n",
        "        {\n",
        "            \"messages\": history_list,\n",
        "        }\n",
        "    )\n",
        "    print(\"AI Says : \",ai_msg.content)\n",
        "\n",
        "    history_list.append(\n",
        "        (\n",
        "            \"ai\",\n",
        "            ai_msg.content,\n",
        "        )\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnGLhdn1LxJI",
        "outputId": "40353192-7f77-4132-f6cb-74fda196ff58"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "안녕\n",
            "## CHAT_HISTORY ##\n",
            "[('human', '안녕')] \n",
            "\n",
            "AI Says :  안녕하세요! 어떻게 도와드릴까요?\n",
            "난 나연이라고 해.\n",
            "## CHAT_HISTORY ##\n",
            "[('human', '안녕'), ('ai', '안녕하세요! 어떻게 도와드릴까요?'), ('human', '난 나연이라고 해.')] \n",
            "\n",
            "AI Says :  안녕하세요, 나연님! 만나서 반갑습니다. 오늘 어떻게 도와드릴까요?\n",
            "그리고 말차를 좋아하지\n",
            "## CHAT_HISTORY ##\n",
            "[('human', '안녕'), ('ai', '안녕하세요! 어떻게 도와드릴까요?'), ('human', '난 나연이라고 해.'), ('ai', '안녕하세요, 나연님! 만나서 반갑습니다. 오늘 어떻게 도와드릴까요?'), ('human', '그리고 말차를 좋아하지')] \n",
            "\n",
            "AI Says :  말차를 좋아하시는군요! 말차는 독특한 맛과 향이 있어서 많은 사람들이 좋아하죠. 말차를 자주 드시나요, 아니면 특별한 때에만 드시나요?\n",
            "내 이름이 뭐였게?\n",
            "## CHAT_HISTORY ##\n",
            "[('human', '안녕'), ('ai', '안녕하세요! 어떻게 도와드릴까요?'), ('human', '난 나연이라고 해.'), ('ai', '안녕하세요, 나연님! 만나서 반갑습니다. 오늘 어떻게 도와드릴까요?'), ('human', '그리고 말차를 좋아하지'), ('ai', '말차를 좋아하시는군요! 말차는 독특한 맛과 향이 있어서 많은 사람들이 좋아하죠. 말차를 자주 드시나요, 아니면 특별한 때에만 드시나요?'), ('human', '내 이름이 뭐였게?')] \n",
            "\n",
            "AI Says :  나연님이시죠? 앞에서 말씀해 주셨습니다. 😊\n",
            "굿\n",
            "## CHAT_HISTORY ##\n",
            "[('human', '안녕'), ('ai', '안녕하세요! 어떻게 도와드릴까요?'), ('human', '난 나연이라고 해.'), ('ai', '안녕하세요, 나연님! 만나서 반갑습니다. 오늘 어떻게 도와드릴까요?'), ('human', '그리고 말차를 좋아하지'), ('ai', '말차를 좋아하시는군요! 말차는 독특한 맛과 향이 있어서 많은 사람들이 좋아하죠. 말차를 자주 드시나요, 아니면 특별한 때에만 드시나요?'), ('human', '내 이름이 뭐였게?'), ('ai', '나연님이시죠? 앞에서 말씀해 주셨습니다. 😊'), ('human', '굿')] \n",
            "\n",
            "AI Says :  감사합니다! 나연님, 다른 궁금한 점이나 이야기가 있으시면 언제든지 말씀해 주세요.\n",
            "종료\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2) Chat history\n",
        "- ChatMessageHistory() 클래스 사용하기\n",
        "- It's perfectly fine to store and pass messages directly as an array, but we can use LangChain's built-in message history class to store and load messages as well."
      ],
      "metadata": {
        "id": "lHsjha-JTVMn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://api.python.langchain.com/en/latest/chat_message_histories/langchain_community.chat_message_histories.in_memory.ChatMessageHistory.html"
      ],
      "metadata": {
        "id": "4EZYo9IoXgMB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.chat_message_histories import ChatMessageHistory\n",
        "\n",
        "chat_history = ChatMessageHistory()\n",
        "\n",
        "chat_history.add_user_message(\n",
        "    \"일본어로 '잘 먹겠습니다.' 어떻게 말해? 한글 발음도 함께 말해줘.\"\n",
        ")\n",
        "\n",
        "chat_history.add_ai_message(\"いただきます (이타다키마스)\")\n",
        "\n",
        "chat_history.messages\n",
        "# chat_history.clear()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82OuUOtETIpI",
        "outputId": "1d75e123-2254-46bf-966c-b01481241bd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content=\"일본어로 '잘 먹겠습니다.' 어떻게 말해? 한글 발음도 함께 말해줘.\", additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='いただきます (이타다키마스)', additional_kwargs={}, response_metadata={})]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 대화내용 바로바로 저장하기"
      ],
      "metadata": {
        "id": "dLOjjo9sWKdf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat_history = ChatMessageHistory()\n",
        "\n",
        "################ USER INPUT - 1 ################\n",
        "input1 = \"일본어로 '잘 먹겠습니다.' 어떻게 말해? 한글 발음도 함께 말해줘.\"\n",
        "\n",
        "# 대화 히스토리에 입력(user_input) 저장\n",
        "chat_history.add_user_message(input1)\n",
        "print(\"첫번째 입력 후 history : \", chat_history.messages)\n",
        "\n",
        "################ AI RESPONSE - 1 ################\n",
        "# 답변 생성(response)\n",
        "response = chain.invoke(\n",
        "    {\n",
        "        \"messages\": chat_history.messages,\n",
        "    }\n",
        ")\n",
        "\n",
        "# 대화 히스토리에 답변(response) 저장\n",
        "chat_history.add_ai_message(response)\n",
        "print(\"첫번째 답변 후 history : \", chat_history.messages)\n",
        "print()\n",
        "\n",
        "################ USER INPUT - 2 ################\n",
        "input2 = \"내가 방금 뭐라고 물어봤지?\"\n",
        "\n",
        "# 대화 히스토리에 입력(user_input) 저장\n",
        "chat_history.add_user_message(input2)\n",
        "print(\"두번째 입력 후 history : \", chat_history.messages)\n",
        "\n",
        "################ AI RESPONSE - 2 ################\n",
        "# 답변 생성(response)\n",
        "print(\"[두번째 입력에 대한 답변]\")\n",
        "chain.invoke(\n",
        "    {\n",
        "        \"messages\": chat_history.messages,\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0msG3hgTVvF",
        "outputId": "6818c7dd-a98a-4581-c9ff-eab36c4c1c75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "첫번째 입력 후 history :  [HumanMessage(content=\"일본어로 '잘 먹겠습니다.' 어떻게 말해? 한글 발음도 함께 말해줘.\", additional_kwargs={}, response_metadata={})]\n",
            "첫번째 답변 후 history :  [HumanMessage(content=\"일본어로 '잘 먹겠습니다.' 어떻게 말해? 한글 발음도 함께 말해줘.\", additional_kwargs={}, response_metadata={}), AIMessage(content='일본어로 \\'잘 먹겠습니다.\\'는 \"いただきます\"라고 말합니다. 한글 발음은 \"이타다키마스\"입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 59, 'total_tokens': 93, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_2f406b9113', 'finish_reason': 'stop', 'logprobs': None}, id='run-1ed0525d-6e28-4e28-9c7a-a8970c5b9c49-0', usage_metadata={'input_tokens': 59, 'output_tokens': 34, 'total_tokens': 93, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})]\n",
            "\n",
            "두번째 입력 후 history :  [HumanMessage(content=\"일본어로 '잘 먹겠습니다.' 어떻게 말해? 한글 발음도 함께 말해줘.\", additional_kwargs={}, response_metadata={}), AIMessage(content='일본어로 \\'잘 먹겠습니다.\\'는 \"いただきます\"라고 말합니다. 한글 발음은 \"이타다키마스\"입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 59, 'total_tokens': 93, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_2f406b9113', 'finish_reason': 'stop', 'logprobs': None}, id='run-1ed0525d-6e28-4e28-9c7a-a8970c5b9c49-0', usage_metadata={'input_tokens': 59, 'output_tokens': 34, 'total_tokens': 93, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}), HumanMessage(content='내가 방금 뭐라고 물어봤지?', additional_kwargs={}, response_metadata={})]\n",
            "[두번째 입력에 대한 답변]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='당신은 \"일본어로 \\'잘 먹겠습니다.\\' 어떻게 말해? 한글 발음도 함께 말해줘.\"라고 물어보셨습니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 112, 'total_tokens': 146, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_e5e4913e83', 'finish_reason': 'stop', 'logprobs': None}, id='run-8a35d5c0-d930-4eef-a5fa-11cf78860163-0', usage_metadata={'input_tokens': 112, 'output_tokens': 34, 'total_tokens': 146, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 응용 : 대화 쌓일 때마다 히스토리 저장하도록 구현"
      ],
      "metadata": {
        "id": "8lNztnwgY5G3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat_history = ChatMessageHistory()\n",
        "\n",
        "while(True):\n",
        "    user_input = input()\n",
        "    if user_input == \"종료\": break\n",
        "    chat_history.add_user_message(user_input)\n",
        "    response = chain.invoke(\n",
        "        {\n",
        "            \"messages\": chat_history.messages,\n",
        "        }\n",
        "    )\n",
        "    chat_history.add_ai_message(response)\n",
        "    print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atmi65POYM12",
        "outputId": "5842e088-b8d0-4b7b-bdde-8bbeca9aeefd"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "안녕!\n",
            "안녕하세요! 무엇을 도와드릴까요?\n",
            "말차로 만든 디저트에는 뭐가 있어?\n",
            "말차로 만든 디저트에는 다양한 종류가 있습니다. 몇 가지 예를 들면:\n",
            "\n",
            "1. **말차 티라미수** - 전통적인 티라미수에 말차를 더해 새로운 맛을 즐길 수 있습니다.\n",
            "2. **말차 마카롱** - 겉은 바삭하고 속은 부드러운 마카롱에 말차 크림을 채워 넣은 디저트입니다.\n",
            "3. **말차 아이스크림** - 부드럽고 진한 말차 맛이 느껴지는 아이스크림입니다.\n",
            "4. **말차 롤케이크** - 부드러운 스폰지 케이크에 말차 크림을 발라 말아서 만든 케이크입니다.\n",
            "5. **말차 브라우니** - 진한 초콜릿 브라우니에 말차를 더해 새로운 풍미를 더한 디저트입니다.\n",
            "6. **말차 푸딩** - 부드럽고 크리미한 말차 맛의 푸딩입니다.\n",
            "7. **말차 파운드 케이크** - 촉촉하고 진한 말차 맛이 느껴지는 파운드 케이크입니다.\n",
            "\n",
            "이 외에도 다양한 창의적인 말차 디저트들이 있으니 시도해보시면 좋을 것 같습니다!\n",
            "이 중에서 가장 만들기 쉬운건 뭘까?\n",
            "말차 디저트 중에서 비교적 만들기 쉬운 것은 **말차 아이스크림**이나 **말차 푸딩**입니다. \n",
            "\n",
            "- **말차 아이스크림**: 아이스크림 제조기에 필요한 재료를 섞어서 얼리기만 하면 되기 때문에 비교적 간단합니다. 만약 아이스크림 제조기가 없다면, 생크림과 연유, 말차 가루를 섞어 냉동실에 얼리면서 중간중간 젓는 방법으로도 만들 수 있습니다.\n",
            "\n",
            "- **말차 푸딩**: 젤라틴을 사용하여 푸딩을 굳히는 방식이라 복잡한 베이킹 기술이 필요하지 않습니다. 우유, 설탕, 말차 가루, 젤라틴을 잘 섞어서 굳히기만 하면 되므로 초보자도 쉽게 만들 수 있습니다.\n",
            "\n",
            "이 두 가지는 비교적 간단한 재료와 과정을 통해 만들 수 있으니 처음 시도해보기 좋습니다.\n",
            "그럼 말차 브라우니는?\n",
            "말차 브라우니는 기본적인 베이킹 기술이 필요하지만, 비교적 간단하게 만들 수 있는 디저트 중 하나입니다. 여기 간단한 말차 브라우니 레시피를 소개해드릴게요.\n",
            "\n",
            "**재료:**\n",
            "- 밀가루 100g\n",
            "- 설탕 150g\n",
            "- 버터 100g\n",
            "- 달걀 2개\n",
            "- 말차 가루 2큰술\n",
            "- 베이킹 파우더 1작은술\n",
            "- 소금 약간\n",
            "- 화이트 초콜릿 칩 (선택사항)\n",
            "\n",
            "**만드는 법:**\n",
            "1. 오븐을 180도로 예열합니다.\n",
            "2. 버터는 녹여서 준비합니다.\n",
            "3. 큰 볼에 녹인 버터와 설탕을 넣고 잘 섞어줍니다.\n",
            "4. 달걀을 하나씩 넣고 거품기로 잘 저어줍니다.\n",
            "5. 체로 친 밀가루, 말차 가루, 베이킹 파우더, 소금을 넣고 주걱으로 잘 섞어줍니다. \n",
            "6. 선택사항으로 화이트 초콜릿 칩을 넣고 섞어줍니다.\n",
            "7. 반죽을 베이킹 틀에 부어 고르게 펼칩니다.\n",
            "8. 예열된 오븐에서 약 20-25분간 구워줍니다. 꼬치로 찔러보아 반죽이 묻어나오지 않으면 완성입니다.\n",
            "9. 오븐에서 꺼내어 식힌 후, 적당한 크기로 잘라서 즐기시면 됩니다.\n",
            "\n",
            "이 레시피를 따라 하면 집에서도 맛있는 말차 브라우니를 쉽게 만들 수 있습니다.\n",
            "종료\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3) Automatic history management\n",
        "- RunnableWithMessageHistory() 활용하여 메모리 관리하기\n",
        "- The previous examples pass messages to the chain explicitly. This is a completely acceptable approach, but it does require external management of new messages. LangChain also includes an wrapper for LCEL chains that can handle this process automatically called RunnableWithMessageHistory."
      ],
      "metadata": {
        "id": "h5IW96A8WNYS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat = ChatOpenAI(model=\"gpt-4o\")\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"You are a helpful assistant. Answer all questions to the best of your ability. YOU MUST ANSWER IN KOREAN.\",\n",
        "        ),\n",
        "        (\"placeholder\", \"{chat_history}\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "chain = prompt | chat"
      ],
      "metadata": {
        "id": "ECXuHzfWWNol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "\n",
        "chat_history_for_chain = ChatMessageHistory()\n",
        "\n",
        "chain_with_message_history = RunnableWithMessageHistory(\n",
        "    chain, # 실행할 Runnable 객체\n",
        "    lambda session_id: chat_history_for_chain, # 세션 기록을 가져오는 함수\n",
        "    input_messages_key=\"input\", # 입력 메시지의 Key\n",
        "    history_messages_key=\"chat_history\", # 대화 히스토리 메시지의 Key\n",
        ")"
      ],
      "metadata": {
        "id": "y2GV7xqWWPGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain_with_message_history.invoke(\n",
        "    {\"input\": \"일본어로 '잘 먹겠습니다.' 어떻게 말해? 한글 발음도 함께 말해줘.\"},\n",
        "    {\"configurable\": {\"session_id\": \"unused\"}},\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0QE2_qxWPkl",
        "outputId": "2a7fd8b4-bb9e-49e6-b992-5f9445971d06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='일본어로 \\'잘 먹겠습니다.\\'는 \"いただきます\"라고 말합니다. 한글 발음은 \"이타다키마스\"입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 59, 'total_tokens': 93, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_e5e4913e83', 'finish_reason': 'stop', 'logprobs': None}, id='run-6ea25a7f-eaa5-4809-81eb-57d41ad37427-0', usage_metadata={'input_tokens': 59, 'output_tokens': 34, 'total_tokens': 93, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain_with_message_history.invoke(\n",
        "    {\"input\": \"내가 뭐라고 물어봤지?\"}, {\"configurable\": {\"session_id\": \"unused\"}}\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5898B2zWRQT",
        "outputId": "8a0777ca-7493-4564-fe0f-ff730ad68a6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='당신은 \"\\'잘 먹겠습니다.\\'를 일본어로 어떻게 말하는지\" 물어보셨습니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 110, 'total_tokens': 133, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_e5e4913e83', 'finish_reason': 'stop', 'logprobs': None}, id='run-50037728-4fa6-4506-ba54-a5d97a92e832-0', usage_metadata={'input_tokens': 110, 'output_tokens': 23, 'total_tokens': 133, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "히스토리 저장 함수를 따로 호출할 필요없이 invoke 실행만으로 대화 기록이 자동 저장되는 것을 확인 가능!"
      ],
      "metadata": {
        "id": "mwFQUG_PgvGv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4) Modifying chat history\n",
        "- 이전 대화 내용을 가공하여 넘겨주기\n",
        "- Modifying stored chat messages can help your chatbot handle a variety of situations."
      ],
      "metadata": {
        "id": "R9HtRAXzfutg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat_history = ChatMessageHistory()\n",
        "\n",
        "chat_history.add_user_message(\"안녕하세요. 제 이름은 나연입니다.\")\n",
        "chat_history.add_ai_message(\"안녕하세요, 나연님! 무엇을 도와드릴까요?\")\n",
        "chat_history.add_user_message(\"날씨 좋은 날 들을만 한 노래 추천해주세요.\")\n",
        "chat_history.add_ai_message(\"Carpenters - Close to you 를 추천해요.\")\n",
        "\n",
        "chat_history.messages\n",
        "# chat_history.clear()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJicGgSXWvkL",
        "outputId": "9b8deca3-bf20-49d8-e38f-049c1d22bd3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content='안녕하세요. 제 이름은 나연입니다.', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='안녕하세요, 나연님! 무엇을 도와드릴까요?', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='날씨 좋은 날 들을만 한 노래 추천해주세요.', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='Carpenters - Close to you 를 추천해요.', additional_kwargs={}, response_metadata={})]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"You are a helpful assistant. Answer all questions to the best of your ability. The provided chat history includes facts about the user you are speaking with. YOU MUST ANSWER IN KOREAN.\",\n",
        "        ),\n",
        "        (\"placeholder\", \"{chat_history}\"),\n",
        "        (\"user\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "chain = prompt | chat\n",
        "\n",
        "chain_with_message_history = RunnableWithMessageHistory(\n",
        "    chain,\n",
        "    lambda session_id: chat_history,\n",
        "    input_messages_key=\"input\",\n",
        "    history_messages_key=\"chat_history\",\n",
        ")"
      ],
      "metadata": {
        "id": "1f7vAPaCWyyE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "def summarize_messages(chain_input):\n",
        "    stored_messages = chat_history.messages\n",
        "    if len(stored_messages) == 0:\n",
        "        return False\n",
        "    summarization_prompt = ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\"placeholder\", \"{chat_history}\"),\n",
        "            (\n",
        "                \"user\",\n",
        "                \"Distill the above chat messages into a single summary message. Include as many specific details as you can.\",\n",
        "            ),\n",
        "        ]\n",
        "    )\n",
        "    summarization_chain = summarization_prompt | chat\n",
        "\n",
        "    # chat_history 에 저장된 대화 기록을 요약프롬프트에 입력 & 결과 저장\n",
        "    summary_message = summarization_chain.invoke({\"chat_history\": stored_messages})\n",
        "\n",
        "    # chat_history 에 저장되어있던 기록 지우기\n",
        "    chat_history.clear()\n",
        "\n",
        "    # 생성된 새로운 요약내용으로 기록 채우기\n",
        "    chat_history.add_message(summary_message)\n",
        "\n",
        "    return True\n",
        "\n",
        "chain_with_summarization = (\n",
        "    RunnablePassthrough.assign(messages_summarized=summarize_messages)\n",
        "    | chain_with_message_history\n",
        ")"
      ],
      "metadata": {
        "id": "NEvcOsdqWzsZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- summarize_messages 함수의 실행 결과를 messages_summarized 라는 이름의 Key 로 저장\n",
        "\n",
        "    - 정의한 chain 안에 \"messages_summarized\" Key 가 정의되고 있지 않으므로, 이는 `summarize_messages` 함수를 실행하기 위한 무시 가능한 Key\n",
        "    - 함수가 실행되면 chat_history 에 요약된 히스토리가 저장됨\n"
      ],
      "metadata": {
        "id": "3Ed_Kcek8kvT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chain_with_summarization.invoke(\n",
        "    {\"input\": \"제 이름을 기억하고 있나요?\"},\n",
        "    {\"configurable\": {\"session_id\": \"unused\"}},\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iq4jhbBBW17O",
        "outputId": "a2a1c7ba-3052-484f-ad32-cf00b70e69ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='네, 나연님이라고 알고 있습니다. 맞나요?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 94, 'total_tokens': 106, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_2f406b9113', 'finish_reason': 'stop', 'logprobs': None}, id='run-0e55a4c3-cc75-4b51-afc6-41fc57f30d60-0', usage_metadata={'input_tokens': 94, 'output_tokens': 12, 'total_tokens': 106, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain_with_summarization.invoke(\n",
        "    {\"input\": \"그 가수는 남자인가요 여자인가요?\"},\n",
        "    {\"configurable\": {\"session_id\": \"unused\"}},\n",
        ")"
      ],
      "metadata": {
        "id": "XtwtUrBcW6eK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1a2913b-265e-4ce4-a1c3-d38588178034"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Carpenters는 남매 듀오로, 리처드 카펜터와 카렌 카펜터로 구성되어 있습니다. 카렌 카펜터는 여성 보컬리스트입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 44, 'prompt_tokens': 109, 'total_tokens': 153, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_e5e4913e83', 'finish_reason': 'stop', 'logprobs': None}, id='run-20fa421b-37ee-49f2-8af2-dbc6ea408fd6-0', usage_metadata={'input_tokens': 109, 'output_tokens': 44, 'total_tokens': 153, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C-goCIryhxk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. 끝말잇기 게임 구현하기\n",
        "\n",
        "- 4) Modifying chat history 의 활용!"
      ],
      "metadata": {
        "id": "Rn0LO7Bdr8nT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 대화 기록을 저장할 히스토리 클래스 불러오기\n",
        "chat_history = ChatMessageHistory()\n",
        "\n",
        "# chat_history.add_user_message(\"끝말잇기 하자\")\n",
        "# chat_history.add_ai_message(\"좋습니다. 제가 먼저 시작할게요. 바나나!\")\n",
        "# chat_history.add_user_message(\"나이테\")\n",
        "# chat_history.add_ai_message(\"테이프\")\n",
        "\n",
        "chat_history.messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27ed50a9-b5bb-458c-db66-6c2550074ded",
        "id": "OpnDi8ZFhx6y"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat = ChatOpenAI(model=\"gpt-4o\")\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"\"\"당신은 끝말잇기 게임을 진행하는 AI 챗봇입니다. 아래는 게임 규칙입니다. 당신과 user 의 입력에서 아래 규칙이 꼭 지켜져야 하며, 지키지 않은 사람에게 패배를 알린 뒤, 끝말잇기 게임을 종료합니다.\n",
        "                1. 주어진 대화 기록에서 이미 나왔던 단어를 다시 말했을 경우 패배합니다.\n",
        "                2. 두음법칙을 허용합니다. (ex. 리 -> 이, 력 -> 역, 락 -> 낙)\n",
        "                3. 국어사전에 존재하는 단어이자, 명사여야 합니다.\n",
        "            \"\"\",\n",
        "        ),\n",
        "        (\"placeholder\", \"{chat_history}\"),\n",
        "        (\"user\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "chain = prompt | chat\n",
        "\n",
        "chain_with_message_history = RunnableWithMessageHistory(\n",
        "    chain,\n",
        "    lambda session_id: chat_history,\n",
        "    input_messages_key=\"input\",\n",
        "    history_messages_key=\"chat_history\",\n",
        ")"
      ],
      "metadata": {
        "id": "dQoRukC8hx6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_messages(chain_input):\n",
        "    stored_messages = chat_history.messages\n",
        "    if len(stored_messages) == 0:\n",
        "        return False\n",
        "    summarization_prompt = ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\"placeholder\", \"{chat_history}\"),\n",
        "            (\n",
        "                \"user\",\n",
        "                \"위 채팅 메시지는 끝말잇기 게임을 진행한 대화내용입니다. 언급한 단어들만 나열하여 저장해주세요.\",\n",
        "            ),\n",
        "        ]\n",
        "    )\n",
        "    summarization_chain = summarization_prompt | chat\n",
        "\n",
        "    # chat_history 에 저장된 대화 기록을 요약프롬프트에 입력 & 결과 저장\n",
        "    summary_message = summarization_chain.invoke({\"chat_history\": stored_messages})\n",
        "\n",
        "    # chat_history 에 저장되어있던 기록 지우기\n",
        "    chat_history.clear()\n",
        "\n",
        "    # 생성된 새로운 요약내용으로 기록 채우기\n",
        "    chat_history.add_message(summary_message)\n",
        "\n",
        "    return True\n",
        "\n",
        "\n",
        "chain_with_summarization = (\n",
        "    RunnablePassthrough.assign(messages_summarized=summarize_messages)\n",
        "    | chain_with_message_history\n",
        ")"
      ],
      "metadata": {
        "id": "BLMCkKMphx6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while(True):\n",
        "    user_input = input(\"🙋‍♂️ YOUR TURN : \")\n",
        "    if user_input == \"종료\": break\n",
        "    response = chain_with_summarization.invoke(\n",
        "                {\"input\": user_input},\n",
        "                {\"configurable\": {\"session_id\": \"unused\"}},\n",
        "            )\n",
        "    print(\"✍ AI TURN : \", response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDn2jJJGiw1a",
        "outputId": "4e539b43-a597-44dd-d41e-e5b959614c01"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🙋‍♂️ YOUR TURN : 바나나\n",
            "✍ AI TURN :  나무\n",
            "🙋‍♂️ YOUR TURN : 무지개\n",
            "✍ AI TURN :  개구리\n",
            "🙋‍♂️ YOUR TURN : 이빨\n",
            "✍ AI TURN :  빨래\n",
            "🙋‍♂️ YOUR TURN : 래미콘\n",
            "✍ AI TURN :  콘서트\n",
            "🙋‍♂️ YOUR TURN : 트럭\n",
            "✍ AI TURN :  럭비\n",
            "🙋‍♂️ YOUR TURN : 비행기\n",
            "✍ AI TURN :  기차\n",
            "🙋‍♂️ YOUR TURN : 차표\n",
            "✍ AI TURN :  표범\n",
            "🙋‍♂️ YOUR TURN : 범고래\n",
            "✍ AI TURN :  래프팅\n",
            "🙋‍♂️ YOUR TURN : 팅팅탱탱\n",
            "✍ AI TURN :  죄송하지만 \"팅팅탱탱\"은 국어사전에 존재하는 명사가 아닙니다. 따라서 규칙을 어기셨습니다. 당신의 패배로 끝말잇기 게임을 종료합니다.\n",
            "🙋‍♂️ YOUR TURN : 종료\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "feZwCT4zsEWh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}